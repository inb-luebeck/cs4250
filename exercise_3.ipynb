{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision SS 2021\n",
    "## Exercise Sheet 3: Image Center, Edges, Keypoints\n",
    "### Erhardt Barth / Philipp Gruening / Christoph Linse / Manuel Laufer\n",
    "Universität zu Lübeck, Institut für Neuro- und Bioinformatik\n",
    "\n",
    "In case of questions, contact us via email: *{barth, gruening, linse, laufer} @inb.uni-luebeck.de*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: Please insert the names of all participating students:\n",
    "\n",
    "1. \n",
    "2. \n",
    "3. \n",
    "4. \n",
    "5. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "  if os.getcwd() == '/content':\n",
    "    !git clone 'https://github.com/inb-luebeck/cs4250.git'\n",
    "    os.chdir('cs4250')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.morphology import dilation\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.1\n",
    "### Finding the Image Center\n",
    "Camera calibration refers to the process of computing the intrinsic and extrinsic parameters of the camera. It is a necessary step in many computer vision applications such as 3D scene reconstruction and recognition. One important intrinsic parameter is the image center. Print out the images `ueb311.jpg` and `ueb312.jpg` and estimate the image centers by using a ruler.\n",
    "\n",
    "**Hint**: Make small printouts of the images to have enough space around them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_gray(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_gray_normalized(image_path):\n",
    "    return load_image_gray(image_path).astype('float32')/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(image):\n",
    "    v = .5\n",
    "    k_y = np.zeros((3, 3))\n",
    "    k_y[0, 1] = -v\n",
    "    k_y[2, 1] = +v\n",
    "\n",
    "    k_x = np.zeros((3, 3))\n",
    "    k_x[1, 0] = -v\n",
    "    k_x[1, 2] = +v\n",
    "\n",
    "    image = np.copy(image).astype('float32')\n",
    "\n",
    "    gradient_x = cv2.filter2D(image, -1, k_x)\n",
    "    gradient_y = cv2.filter2D(image, -1, k_y)\n",
    "\n",
    "    return gradient_x, gradient_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.2.1\n",
    "### Edge Detection\n",
    "Open the image `ueb32.jpg` in Python and show the image gradients $d_x$ and $d_y$. Compute the magnitude of gradients image and apply a threshold to retain only the edges of the object. For those edges, compute and show the gradient angle image (`np.arctan2`). How can you tell the angle of the gradient from looking only at the gradients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "\n",
    "# smooth image\n",
    "\n",
    "# compute and show gradient images \n",
    "# make images comparable\n",
    "\n",
    "# compute gradient magnitude\n",
    "\n",
    "# compute an angle image that should be in range [-180,+180]\n",
    "\n",
    "# show angles only for real edges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.2.2\n",
    "### Canny Edge Detector\n",
    "Open the image `ueb32.jpg` in Python and use the OpenCV Canny algorithm to find the edges in the image.\n",
    "Compare the result with the magnitude of gradient image. Display both results side by side using `plt.subplots`.\n",
    "Comment on how the two results differ and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "# compute magnitude of gradient image\n",
    "# apply canny\n",
    "# compare results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.3\n",
    "### Key Point Detection\n",
    "Implement the following key-point detectors:\n",
    "* local maxima of $K$\n",
    "* local maxima of $K$ − $\\alpha$ $H^2$, with $\\alpha$ as weighting parameter\n",
    "\n",
    "The function is supposed to return images of the same size as the input, where the pixels contain $K$ or $K$ − $\\alpha$ $H^2$.\n",
    "\n",
    "$K$ and $H$ should be the invariants of the structure tensor $J$ (see script).\n",
    "Evaluate the detectors above on two kinds of test images: (i) the synthetic image `ueb331.npy`, (ii) the\n",
    "picture `ueb332.jpg`.\n",
    "\n",
    "Comment your results with a focus on\n",
    "1. the localization of the key points\n",
    "2. the influence of the $H$ term as controlled via the parameter $\\alpha$.\n",
    "\n",
    "**Question**: Why do you filter the image with a Gaussian kernel a second time? It is **not** about noise removal!\n",
    "\n",
    "**Hint**: Use the provided functions `find_local_max` and `plot_marks`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_local_max(keypoints, thres=1e-6, k=3):\n",
    "    kernel = np.ones((k, k))\n",
    "    kernel[k//2, k//2] = 0\n",
    "    local_max = keypoints > thres + dilation(keypoints, kernel)\n",
    "\n",
    "    return local_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_marks(map, ax=None):\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(1)\n",
    "    col, row = np.nonzero(map)\n",
    "\n",
    "    ax.plot(row, col, 'r.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_points_structure(image, alpha, sigma=.1):\n",
    "    pass\n",
    "    # image parameters\n",
    "\n",
    "    # 0. filter with Gaussian kernel with sigma\n",
    "\n",
    "    # 1. partial derivatives\n",
    "\n",
    "    # 2. product images\n",
    "\n",
    "    # 3. filter with gaussian kernel with sigma = 1\n",
    "\n",
    "    # 4. compute invarians for J\n",
    "\n",
    "    # return K, K_minus_H\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define alpha, sigma, and k\n",
    "\n",
    "# load images\n",
    "\n",
    "# extract keypoints\n",
    "\n",
    "# show found keypoints (K, K_minus_H) for both images\n",
    "# example\n",
    "\"\"\"\n",
    "_, ax = plt.subplots(2, 2, figsize=(15, 15))\n",
    "local_max = find_local_max(keypoints_K)\n",
    "ax[0][0].imshow(image)\n",
    "plot_marks(local_max, ax[0][0])\n",
    "\n",
    "local_max = find_local_max(keypoints_K_minus_H)\n",
    "ax[0][1].imshow(image)\n",
    "plot_marks(local_max, ax[0][1])\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}