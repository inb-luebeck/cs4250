{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision\n",
    "## Exercise Sheet 4: Greedy snake\n",
    "### Erhardt Barth / Christoph Linse / Manuel Laufer / Kathleen Anderson\n",
    "Universität zu Lübeck, Institut für Neuro- und Bioinformatik\n",
    "\n",
    "In case of questions, contact us via email: *{erhardt.barth, c.linse, m.laufer, k.anderson} @uni-luebeck.de*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: Please insert the names of all participating students:\n",
    "\n",
    "1. \n",
    "2. \n",
    "3. \n",
    "4. \n",
    "5. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "  if os.getcwd() == '/content':\n",
    "    !git clone 'https://github.com/inb-luebeck/cs4250.git'\n",
    "    os.chdir('cs4250')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, a program framework is given. Add the missing parts for the implementation of a greedy \n",
    "snake at the marked sections in the code.\n",
    "\n",
    "* Use the gradient magnitude as image term.\n",
    "* Calculate the three energy terms $E_{cont}$, $E_{curv}$, and $E_{imag}$.\n",
    "* Normalize the energy terms over the neighborhood to the intervall $[0,1]$.\n",
    "* Estimate the point in the neighborhood, that has minimum energy.\n",
    "\n",
    "\n",
    "**Hint:** Use the following equations for the implementation of the energy terms:\\\\\n",
    "\\begin{eqnarray}\n",
    "E_{cont} & = & (0.5\\cdot(\\|p_i-p_{i-1}\\|-\\|p_i-p_{i+1}\\|))^2 \\\\\n",
    "E_{curv} & = & \\|p_{i-1}-2 p_i+p_{i+1}\\|^2 \\\\\n",
    "E_{imag} & = & -\\|\\nabla I(x,y)\\|\n",
    "\\end{eqnarray}\n",
    "\n",
    "Comment on the difference between using $E_{cont}$ described above and the term $(\\bar d-\\|p_i-p_{i-1}\\|)^2$ given in the lecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snake(img, contour, **kwargs):\n",
    "    # parameter initialization\n",
    "    k = contour.shape[1]\n",
    "    alpha = kwargs['alpha'] * np.ones(k)\n",
    "    beta = kwargs['beta'] * np.ones(k)\n",
    "    gamma = kwargs['gamma'] * np.ones(k)\n",
    "\n",
    "    # TODO: compute gradient image\n",
    "\n",
    "    k_updated = k\n",
    "    iterations = 0\n",
    "    # iterate until snake stops changing\n",
    "    while k_updated > k * kwargs['contour_fraction']:\n",
    "        iterations = iterations + 1\n",
    "        k_updated = 0\n",
    "        \n",
    "        # update all contour points\n",
    "        for i in range(k):\n",
    "            p, updated = greedy_minimization(\n",
    "                norm_image_gradient, contour, i, alpha, beta, gamma, kwargs['neighborhood_size'])\n",
    "            if p is not None:\n",
    "                contour[:, i] = p\n",
    "            # eliminate corners if required\n",
    "            if iterations > kwargs['begin_corner_elim']:\n",
    "                beta = corner_elimination(contour, beta, kwargs['K_threshold'])\n",
    "            \n",
    "            # keep track of number of updated points\n",
    "            if updated:\n",
    "                k_updated = k_updated + 1\n",
    "        \n",
    "        # display current state of snake\n",
    "        print('num_updates: {}'.format(k_updated))\n",
    "        plt.imshow(norm_image_gradient)\n",
    "        plt.plot(contour[1, :], contour[0, :], 'r.-')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_minimization(norm_image_gradient, contour, i, alpha, beta, gamma, neighborhood_size):\n",
    "    m, n = norm_image_gradient.shape\n",
    "    k = contour.shape[1]\n",
    "    w = (kwargs['neighborhood_size'] - 1.) // 2.\n",
    "    d = average_distance(contour)\n",
    "    updated = False\n",
    "\n",
    "    # get previous, current, and next point in snake\n",
    "    p_iminus1 = contour[:, wrap_index(i-1, k)]\n",
    "    p_i = contour[:, i]\n",
    "    p_iplus1 = contour[:, wrap_index(i+1, k)]\n",
    "\n",
    "    # compute individual terms of energy functional\n",
    "    p = []\n",
    "    E_cont = []\n",
    "    E_curv = []\n",
    "    E_imag = []\n",
    "\n",
    "    # For all points in a local neighborhood, compute the energy terms\n",
    "    for p_i_x in np.arange(max(0, p_i[0] - w), min(m-1, p_i[0]+w)+1):\n",
    "        for p_i_y in np.arange(max(0, p_i[1]-w), min(n-1, p_i[1]+w)+1):\n",
    "            pass\n",
    "            # TODO: get the respective vector\n",
    "\n",
    "            # TODO: compute energy terms\n",
    "\n",
    "    if not p:\n",
    "        return None, False\n",
    "\n",
    "    # TODO: normalize individual terms of energy functional\n",
    "\n",
    "    # compute energy functional and determine minimum\n",
    "    new_p_i = p_i\n",
    "    \n",
    "    # determine if the current point of snake was moved\n",
    "    if (p_i - new_p_i).sum() != 0:\n",
    "        updated = True\n",
    "    \n",
    "    return new_p_i, updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(image):\n",
    "    v = .5\n",
    "    k_y = np.zeros((3, 3))\n",
    "    k_y[0, 1] = -v\n",
    "    k_y[2, 1] = +v\n",
    "\n",
    "    k_x = np.zeros((3, 3))\n",
    "    k_x[1, 0] = -v\n",
    "    k_x[1, 2] = +v\n",
    "\n",
    "    image = np.copy(image).astype('float32')\n",
    "\n",
    "    gradient_x = cv2.filter2D(image, -1, k_x)\n",
    "    gradient_y = cv2.filter2D(image, -1, k_y)\n",
    "\n",
    "    return gradient_x, gradient_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_gray_normalized(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return image.astype('float32')/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_index(index, k):\n",
    "    if index < 0:\n",
    "        index = k - 1\n",
    "    elif index > k-1:\n",
    "        index = 0\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_distance(contour):\n",
    "    avg_dist = 0\n",
    "    n = contour.shape[1]\n",
    "\n",
    "    for i in range(n-1):\n",
    "        avg_dist = avg_dist+norm(contour[:, i] - contour[:, i+1])\n",
    "\n",
    "    avg_dist = avg_dist+norm(contour[:, -1] - contour[:, 0])\n",
    "    avg_dist = avg_dist / n\n",
    "\n",
    "    return avg_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corner_elimination(contour, beta, K_threshold):\n",
    "    n = contour.shape[1]\n",
    "    K = []\n",
    "    # compute curvature of snake at each point\n",
    "    for i in range(n):\n",
    "        # get previous, current, and next point in snake\n",
    "        p_iminus1 = contour[:, wrap_index(i-1, n)]\n",
    "        p_i = contour[:, i]\n",
    "        p_iplus1 = contour[:, wrap_index(i+1, n)]\n",
    "        K.append(((p_iminus1 - 2.*p_i + p_iplus1)**2.).sum())\n",
    "\n",
    "    # determine local maxima and set beta to zero there\n",
    "    for i in range(n):\n",
    "        prev_is_lower = K[wrap_index(i-1, n)] < K[i]\n",
    "        next_is_lower = K[i] > K[wrap_index(i+1, n)]\n",
    "        thres_exceeded = K[i] > K_threshold\n",
    "        if prev_is_lower and next_is_lower and thres_exceeded:\n",
    "            beta[i] = 0\n",
    "    \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your implementation of the greedy snake on the provided test images. The files `ueb421.npy` and\n",
    "`ueb422.npy` contain simple artificial test images. The file `ueb423.npy` contains a natural image. \n",
    "Besides the test images `img`, the files contain a initialization for the snake `contour`.\n",
    "\n",
    "You need to fit the parameter dict `kwargs` to achive good results on the different images.\n",
    "**What are the relevant parameters, and what is their influence on the resulting segmentation?**\n",
    "\n",
    "**Debug Tips**: For debugging, it makes sense to test each functionality separately. For example, set alpha and beta to zero and gamma to one. The contour-points should converge to image edges. If this is not the case, something is wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "input_dict = np.load('data/exercise_4/ueb422.npy', allow_pickle=True).item()\n",
    "image = input_dict['img']\n",
    "contour = input_dict['contour']\n",
    "\n",
    "# show initial image & contour\n",
    "plt.imshow(image)\n",
    "plt.plot(contour[1, :], contour[0, :], 'r.-')\n",
    "plt.show()\n",
    "\n",
    "# set keyword arguments\n",
    "kwargs = {\n",
    "    'neighborhood_size': 7,\n",
    "    'contour_fraction': 0.1,\n",
    "    'alpha': 1.,\n",
    "    'beta': 1.,\n",
    "    'gamma': 1.,\n",
    "    'begin_corner_elim': 10,\n",
    "    'K_threshold': 1\n",
    "}\n",
    "\n",
    "# run snake\n",
    "snake(image, contour, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "input_dict = np.load('data/exercise_4/ueb421.npy', allow_pickle=True).item()\n",
    "image = input_dict['img']\n",
    "contour = input_dict['contour']\n",
    "\n",
    "# show initial image & contour\n",
    "plt.imshow(image)\n",
    "plt.plot(contour[1, :], contour[0, :], 'r.-')\n",
    "plt.show()\n",
    "\n",
    "# set keyword arguments\n",
    "kwargs = {\n",
    "    'neighborhood_size': 7,\n",
    "    'contour_fraction': 0.1,\n",
    "    'alpha': 1.,\n",
    "    'beta': 1.,\n",
    "    'gamma': 1.,\n",
    "    'begin_corner_elim': 10,\n",
    "    'K_threshold': 1\n",
    "}\n",
    "\n",
    "# run snake\n",
    "snake(image, contour, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "input_dict = np.load('data/exercise_4/ueb423.npy', allow_pickle=True).item()\n",
    "image = input_dict['img']\n",
    "contour = input_dict['contour']\n",
    "\n",
    "# show initial image & contour\n",
    "plt.imshow(image)\n",
    "plt.plot(contour[1, :], contour[0, :], 'r.-')\n",
    "plt.show()\n",
    "\n",
    "# set keyword arguments\n",
    "kwargs = {\n",
    "    'neighborhood_size': 7,\n",
    "    'contour_fraction': 0.1,\n",
    "    'alpha': 1.,\n",
    "    'beta': 1.,\n",
    "    'gamma': 1.,\n",
    "    'begin_corner_elim': 10,\n",
    "    'K_threshold': 1\n",
    "}\n",
    "# run snake\n",
    "snake(image, contour, **kwargs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}