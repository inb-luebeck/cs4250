{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision SS 2021\n",
    "## Exercise Sheet 5: Correlation-based Stereo Vision\n",
    "### Erhardt Barth / Philipp Gruening / Christoph Linse / Manuel Laufer\n",
    "Universität zu Lübeck, Institut für Neuro- und Bioinformatik\n",
    "\n",
    "In case of questions, contact us via email: *{barth, gruening, linse, laufer} @inb.uni-luebeck.de*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: Please insert the names of all participating students:\n",
    "\n",
    "1. \n",
    "2. \n",
    "3. \n",
    "4. \n",
    "5. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "  if os.getcwd() == '/content':\n",
    "    !git clone 'https://github.com/inb-luebeck/cs4250.git'\n",
    "    os.chdir('cs4250')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-correlation and Autocorrelation\n",
    "*Cross correlation* is a standard way to estimate the degree of similarity (correlation) between two signals. For a discrete series it is defined as \n",
    "$$\\rho(dt)=\\frac{\\sum_{i}{[(x_i-\\mu_{x})(y_{i+dt}-\\mu_{y})]}}{\\sqrt{\\sum_{i}{(x_i-\\mu_{x})^2}}\\sqrt{\\sum_{i}{(y_{i+dt}-\\mu_{y})^2}}}$$ \n",
    "where $\\rho$ denotes the *correlation coefficient*; $dt$ is the time shift, and $\\mu_{x}$ and $\\mu_{y}$ are the means of the two signals $x$ and $y$. The denominator normalizes the correlation coefficient such that $\\rho \\in [-1,1]$, the bounds indicate maximum correlation and $0$ means no correlation at all. The sums are only evaluated for indices where both $x_i$ and $y_{i+dt}$ exist.\n",
    "\n",
    "When the correlation of a signal is computed against a temporally shifted version of itself, we call it *autocorrelation*, and define it as \n",
    "$$\\rho(dt)=\\frac{\\sum_{i}{[(x_i-\\mu_{x})(x_{i+dt}-\\mu_{x})]}}{(x_i-\\mu_{x})^2}.$$ \n",
    "\n",
    "Cross-correlation can be used to determine the delay between two signals. In order to do this, we shift the second signal across a range of time shifts $[-dt, dt]$ and cross-correlate it with the first signal. The point of maximum correlation corresponds to the signal delay. \n",
    "\n",
    "Write a Python function to calculate the cross-correlation between two signals for the range of delays $[-dt,dt]$.\n",
    "\n",
    "The `ultrasound.npy` data file from the archive contains two ultrasound signals. Plot the two signals in one plot. Using the above algorithm, cross-correlate them to find the signal delay (using a maximum time shift of 100). Plot the values of the correlation coefficient for the given delay range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_corr_seq(X, Y, dt):\n",
    "    # returns the cross-correlation sequence over \n",
    "    # the time shift range [-dt,dt]\n",
    "\n",
    "    rho_seq=[]\n",
    "    for t in np.arange(-dt, dt):\n",
    "        rho = cross_corr(X, Y, t)\n",
    "        rho_seq.append(rho)\n",
    "\n",
    "    return np.array(rho_seq)\n",
    "\n",
    "def cross_corr(X, Y, dt):\n",
    "    # TODO: compute the correlation coeff. for time shift dt\n",
    "    rho = -2.\n",
    "\n",
    "    return rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =np.load('data/exercise_5/ultrasound.npy', allow_pickle=True)\n",
    "Y = X.tolist()['Y'][0]\n",
    "X = X.tolist()['X'][0]\n",
    "\n",
    "_, ax = plt.subplots(1)\n",
    "plt.plot(X, '-b')\n",
    "plt.plot(Y, '-r')\n",
    "ax.set_title('The two ultrasound signals')\n",
    "\n",
    "# TODO: compute cross correlation\n",
    "dt=42\n",
    "rho_seq=cross_corr_seq(X, Y, dt)\n",
    "max_idx = np.argmax(rho_seq)\n",
    "max_rho = rho_seq.max()\n",
    "\n",
    "# TODO: compute lag value\n",
    "lag = 42 \n",
    "print('The signal lag is {}.'.format(lag))\n",
    "\n",
    "_, ax = plt.subplots(1)\n",
    "ax.plot(np.arange(-dt,dt),rho_seq)\n",
    "ax.set_title(\n",
    "    'cross-correlation sequence over the lag range [{},{}]'.format(\n",
    "    -dt, dt)\n",
    ")\n",
    "\n",
    "_, ax = plt.subplots(1)\n",
    "plt.plot(X, '-b')\n",
    "plt.plot(Y[lag:], '-r')\n",
    "ax.set_title('Two signals with adjusted lag')\n",
    "print('Signal difference after lag-adjustment:')\n",
    "print((X[:-lag]-Y[lag:]).sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation-based stereo algorithms\n",
    "\n",
    "In this exercise, we will deal with the first problem of stereo vision:  the *correspondence problem*. For each image point in the left image, we want to find the corresponding point in the right image which is the projection of the same 3D-point.\n",
    "\n",
    "**Keep in mind**: x denotes the horizontal axis of an image, in a numpy matrix this is the second axis (column x). Accordingly, y is the vertical axis in an image, which is the first axis in a numpy matrix (row y).\n",
    "\n",
    "Our basic assumption is that corresponding image regions are similar, i.e. correlated. For each image pixel in the left image we are searching for its best match in the right image (or vice versa). Matching only single pixels results in too many false positives, so we choose a neighborhood window around the pixel and correlate it with all candidate blocks in the right image to find its best match (*block matching*). We assume rectified images, i.e. the epipolar lines are aligned, so we only need to search along the horizontal direction.\n",
    "\n",
    "\n",
    "Possible similarity measures for block matching:\n",
    "\n",
    "* Sum of Squared Differences (SSD): $$D(x,y,dx,dy)=\\sum_{(i,j)\\in W_{x,y}}{[I_l(i,j)-I_r(i-dx, j-dy)]^2}$$\n",
    "* Normalized Cross-correlation (NCC): $$D(x,y,dx,dy)=\\frac{\\sum_{(i,j) \\in W_{x,y}}{I_l(i,j) I_r(i-dx, j-dy)} } {\\sqrt{\\sum_{(i,j)\\in W_{x,y}}{I_{l}^{2} (i,j)} \\sum_{(i,j)\\in W_{x,y}}{I_{r}^{2}{(i-dx, j-dy)} } } }$$\n",
    "\n",
    "where $W_{x,y}$ is the square window of a certain size centered around pixel $(x,y)$, $I_l$ and $I_r$ are the left and right intensity images, and $(dx, dy)$ are the horizontal and vertical *disparities* (shifted amounts). Note that $dx$ is zero as we are only searching for horizontal shifts.\n",
    "\n",
    "The goal is to find for each pixel $(x,y)$ the disparity $(0,dy)$ that either minimizes the error (sum of squared differences) or maximizes the similarity (cross-correlation). \n",
    "In order to do this, we need to search over a range of disparities up to an allowed maximum disparity. \n",
    "The output is the so-called `disparity map`: a map where pixel intensities describe the relative depth of points within a scene.\n",
    "\n",
    "Implement functions `stereo_corr_...(left, right, win_size, max_disp)` which returns the disparity map `disp_map` for the stereo image pair `left` and `right`, given a correlation window size `win_size` and an upper limit on the allowed disparity range `max_disp`. Implement both the SSD and NCC-based block matching and match from left to right (i.e., for each window in the left image, search in the right image, so that the disparity map is with respect to the left image). \n",
    "\n",
    "Note: When coded as nested `for` loops in python, this can be very slow. Be creative about how you code this. Using **convolution** (e.g. `cv2.blur`) is one possibility.\n",
    "\n",
    "Use the stereo image pair `left.jpg` and `right.jpg` in the archive to test your algorithm. You may assume that the images are rectified. Visualize the resulting disparity map with the `plt.imshow` command.\n",
    "\n",
    "Experiment with the following and explain the effects:\n",
    "\n",
    "* try out different window sizes (e.g. `win_size` 3, 5, 9, 11),\n",
    "* try out different values of maximum disparity (e.g. 10, 16),\n",
    "* compare the results obtained with SSD and NCC.\n",
    "\n",
    "**Task**: Find an example where NCC clearly outperforms SDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stereo_corr_ssd(left, right, win_size, max_disp, use_convolution=False):\n",
    "    \"\"\"Computes the disparity map (from left to right) for a stereo image pair subject \n",
    "    to a maximum allowed disparity using Sum of Squared Differences as \n",
    "    similarity measure.\n",
    "    It assumes rectified images (search only in the horizontal direction).\n",
    "\n",
    "    In: \n",
    "       left, right: the left and right images in the stereo pair\n",
    "       win_size: correlation window size\n",
    "       max_disp: upper bound on the allowed disparity\n",
    "    Out:\n",
    "       disparity_map: disparity map of the same size as the input\n",
    "    \"\"\"\n",
    "\n",
    "    not_same_size = len([1 for x,y in zip(left.shape, right.shape) if x!=y]) > 0\n",
    "    if not_same_size:\n",
    "        raise ValueError('The images should have the same size.')\n",
    "    \n",
    "    height, width = left.shape[0], left.shape[1]\n",
    "\n",
    "    # TODO: compute squared diff-based disparity map\n",
    "    \n",
    "    if use_convolution:\n",
    "        pass\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "    for d in range(max_disp):\n",
    "        if use_convolution:\n",
    "            pass\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    \n",
    "    disparity_map = 42*np.ones((height, width))\n",
    "    return disparity_map              \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stereo_corr_NCC(left, right, win_size, max_disp):\n",
    "    \"\"\"Computes the disparity map (from left to right) for a stereo image pair subject \n",
    "    to a maximum allowed disparity using Normalized Cross-Correlation as \n",
    "    similarity measure.\n",
    "    It assumes rectified images (search only in the horizontal direction).\n",
    "\n",
    "    In: \n",
    "       left, right: the left and right images in the stereo pair\n",
    "       win_size: correlation window size\n",
    "       max_disp: upper bound on the allowed disparity\n",
    "    Out:\n",
    "       disparity_map: disparity map of the same size as the input\n",
    "    \"\"\"\n",
    "    \n",
    "    not_same_size = len([1 for x,y in zip(left.shape, right.shape) if x!=y]) > 0\n",
    "    if not_same_size:\n",
    "        raise ValueError('The images should have the same size.')\n",
    "    \n",
    "    height, width = left.shape[0], left.shape[1]\n",
    "    \n",
    "    # TODO: compute correlation-based disparity map\n",
    "    \n",
    "    disparity_map = 13*np.ones((height, width))\n",
    "    return disparity_map            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images\n",
    "left = cv2.cvtColor(cv2.imread('data/exercise_5/left.jpg'), cv2.COLOR_RGB2GRAY).astype('float32')/255.\n",
    "right = cv2.cvtColor(cv2.imread('data/exercise_5/right.jpg'), cv2.COLOR_RGB2GRAY).astype('float32')/255.\n",
    "\n",
    "# TODO: define parameters\n",
    "win_sizes_ = [3]\n",
    "max_disps_ = [5]\n",
    "\n",
    "for win_size in win_sizes_:\n",
    "    for max_disp in max_disps_:\n",
    "        disparity_map_ssd = stereo_corr_ssd(left, right, win_size, max_disp)\n",
    "        disparity_map_NCC = stereo_corr_NCC(left, right, win_size, max_disp)\n",
    "        \n",
    "        _, ax = plt.subplots(1)\n",
    "        ax.imshow(disparity_map_ssd)\n",
    "        ax.set_title('SSD: win_size: {}, max_disp: {}'.format(win_size, max_disp))\n",
    "        \n",
    "        _, ax = plt.subplots(1)\n",
    "        ax.imshow(disparity_map_NCC)\n",
    "        ax.set_title('NCC: win_size: {}, max_disp: {}'.format(win_size, max_disp))\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
